{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophia-moore/232-Final-Project/blob/main/code_diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "906d12ea",
      "metadata": {
        "id": "906d12ea"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "diffusion_maps.py\n",
        "-----------------\n",
        "End-to-end helpers to\n",
        "\n",
        "1. fit a Diffusion-Maps basis on training data           → Z_train   (n_train × k)\n",
        "2. embed out-of-sample (test) observations by Nyström    → Z_test    (n_test  × k)\n",
        "( sparse neighbourhood graph  +  symmetric eigenproblem )\n",
        "\n",
        "\n",
        "Notation matches the description you supplied:\n",
        "\n",
        "    • W_{ij}  =  κ(x_i , x_j)              (Gaussian kernel)\n",
        "    • P       =  D⁻¹ W                    (row-stochastic transition matrix)\n",
        "    • P Ψ   = Ψ Λ                         (right eigenvectors / eigenvalues)\n",
        "    • Z_train = Ψ[:,1:K+1] · diag(Λ[1:K+1] ** (t/2))\n",
        "\n",
        "    • For a new point  x* :\n",
        "        w*_j      = κ(x*, x_j)\n",
        "        p*_j      = w*_j / Σ_j w*_j\n",
        "        φ_i(x*)   = (1 / λ_i) · Σ_j p*_j · φ_i(x_j)\n",
        "        z_i(x*)   = λ_i ** (t/2) · φ_i(x*)\n",
        "\n",
        "Dependencies\n",
        "------------\n",
        "numpy, scipy, scikit-learn  (for pairwise distances only)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import pandas as pd\n",
        "from scipy.sparse.linalg import eigs\n",
        "from scipy.sparse.linalg import eigsh              # sparse symmetric eigen-solver\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.utils.extmath import randomized_svd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78cf7581",
      "metadata": {
        "id": "78cf7581"
      },
      "outputs": [],
      "source": [
        "# --------------------------------------------------------------------- #\n",
        "# 1. utilities                                                          #\n",
        "# --------------------------------------------------------------------- #\n",
        "\n",
        "def _bandwidth_median(distances_sq):\n",
        "    \"\"\"Median distance heuristic for σ (√median of squared dists).\"\"\"\n",
        "    return np.sqrt(np.median(distances_sq))\n",
        "\n",
        "\n",
        "def _symmetric_knn_rbf(X, n_neighbors=30, sigma='median', n_jobs=-1):\n",
        "    \"\"\"\n",
        "    k-NN graph with RBF weights.  Returns W (csr) and sqrt(degrees).\n",
        "    \"\"\"\n",
        "    nbrs = NearestNeighbors(\n",
        "        n_neighbors=n_neighbors,\n",
        "        metric=\"euclidean\",\n",
        "        algorithm=\"auto\",\n",
        "        n_jobs=n_jobs,\n",
        "    ).fit(X)\n",
        "\n",
        "    dists, idx = nbrs.kneighbors(X, return_distance=True)\n",
        "    dists_sq = dists ** 2\n",
        "\n",
        "    if sigma == \"median\":\n",
        "        sigma = _bandwidth_median(dists_sq)\n",
        "    sigma2 = sigma ** 2\n",
        "\n",
        "    weights = np.exp(-dists_sq / sigma2)\n",
        "\n",
        "    # Build sparse matrix\n",
        "    n_samples = X.shape[0]\n",
        "    row_idx = np.repeat(np.arange(n_samples), n_neighbors)\n",
        "    W = sp.csr_matrix(\n",
        "        (weights.ravel(), (row_idx, idx.ravel())),\n",
        "        shape=(n_samples, n_samples),\n",
        "    )\n",
        "\n",
        "    # Symmetrise -- keep the *maximum* weight for each edge\n",
        "    W = W.maximum(W.T)\n",
        "\n",
        "    # Degrees and  D^{-1/2}\n",
        "    deg = np.asarray(W.sum(axis=1)).ravel()\n",
        "    inv_sqrt_deg = 1.0 / np.sqrt(np.clip(deg, 1e-12, None))\n",
        "\n",
        "    return W, inv_sqrt_deg, sigma\n",
        "\n",
        "\n",
        "def _normalized_graph_laplacian(W, inv_sqrt_deg):\n",
        "    \"\"\"\n",
        "    Return the symmetric normalised affinity S = D^{-1/2} W D^{-1/2}.\n",
        "    \"\"\"\n",
        "    D_inv_sqrt = sp.diags(inv_sqrt_deg)\n",
        "    return D_inv_sqrt @ W @ D_inv_sqrt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cc8802d",
      "metadata": {
        "id": "4cc8802d"
      },
      "outputs": [],
      "source": [
        "# --------------------------------------------------------------------- #\n",
        "# 2. training phase                                                     #\n",
        "# --------------------------------------------------------------------- #\n",
        "\n",
        "def fit_diffusion_map(\n",
        "    X_train,\n",
        "    n_components=10,\n",
        "    n_neighbors=30,\n",
        "    sigma=\"median\",\n",
        "    t=2,\n",
        "    n_jobs=-1,\n",
        "    random_state=0,\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute diffusion coordinates for the training set.\n",
        "    Returns (λ,  Φ_train,  Z_train,  helper_dict)\n",
        "    \"\"\"\n",
        "    W, inv_sqrt_deg, sigma = _symmetric_knn_rbf(\n",
        "        X_train, n_neighbors, sigma, n_jobs\n",
        "    )\n",
        "    S = _normalized_graph_laplacian(W, inv_sqrt_deg)\n",
        "\n",
        "    # eigsh on symmetric S  (largest algebraic eigenvalues)\n",
        "    vals, vecs = eigsh(\n",
        "        S,\n",
        "        k=n_components + 1,          # +1 for trivial λ₁ = 1\n",
        "        which=\"LA\",\n",
        "        tol=1e-4,\n",
        "        maxiter=300,\n",
        "    )\n",
        "\n",
        "    # sort high → low\n",
        "    order = np.argsort(-vals)\n",
        "    vals, vecs = vals[order], vecs[:, order]\n",
        "\n",
        "    # drop trivial component\n",
        "    lam  = vals[1 : n_components + 1]\n",
        "    phi  = vecs[:, 1 : n_components + 1]\n",
        "\n",
        "    # diffusion coordinates\n",
        "    Z = phi * lam ** (t / 2)\n",
        "\n",
        "    helpers = dict(\n",
        "        sigma=sigma,\n",
        "        inv_sqrt_deg=inv_sqrt_deg,\n",
        "        phi_train=phi,\n",
        "        lam=lam,\n",
        "        n_neighbors=n_neighbors,\n",
        "        n_jobs=n_jobs,\n",
        "    )\n",
        "    return lam, phi, Z, helpers\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------- #\n",
        "# 3. Nyström out-of-sample                                              #\n",
        "# --------------------------------------------------------------------- #\n",
        "\n",
        "def nystrom_embed(\n",
        "    X_test,\n",
        "    X_train,\n",
        "    helpers,\n",
        "    t=2,\n",
        "):\n",
        "    \"\"\"\n",
        "    Embed X_test into the diffusion space learnt on X_train (Nyström).\n",
        "    \"\"\"\n",
        "    sigma        = helpers[\"sigma\"]\n",
        "    n_neighbors  = helpers[\"n_neighbors\"]\n",
        "    n_jobs       = helpers[\"n_jobs\"]\n",
        "    phi_train    = helpers[\"phi_train\"]   # shape (n_train, n_components)\n",
        "    lam          = helpers[\"lam\"]         # shape (n_components,)\n",
        "    inv_sqrt_deg = helpers[\"inv_sqrt_deg\"]\n",
        "\n",
        "    # neighbor search\n",
        "    nbrs = NearestNeighbors(\n",
        "        n_neighbors=n_neighbors,\n",
        "        metric=\"euclidean\",\n",
        "        algorithm=\"auto\",\n",
        "        n_jobs=n_jobs,\n",
        "    ).fit(X_train)\n",
        "\n",
        "    dists, idx = nbrs.kneighbors(X_test, return_distance=True)\n",
        "    d2 = dists ** 2\n",
        "    weights = np.exp(-d2 / (sigma ** 2))\n",
        "\n",
        "    # normalize to one-step transition probabilities\n",
        "    p_star = weights / weights.sum(axis=1, keepdims=True)  # shape (n_test, n_neighbors)\n",
        "\n",
        "    # now compute Φ_test: weighted sum of phi_train over the neighbors\n",
        "    #   for each test i:  Φ_test[i, :] = Σ_j p_star[i,j] * phi_train[ idx[i,j], : ]\n",
        "    # we can do this in one vectorized step:\n",
        "    #   gather the relevant phi_train rows,\n",
        "    #   multiply by p_star[..., None], then sum over neighbour-axis.\n",
        "\n",
        "    # shape (n_test, n_neighbors, n_components)\n",
        "    phi_neigh = phi_train[idx]\n",
        "\n",
        "    # weight & sum → (n_test, n_components)\n",
        "    Phi_test = np.einsum(\"ij, ijk -> ik\", p_star, phi_neigh)\n",
        "\n",
        "    # Divide by eigenvalues and scale by lambda^(t/2)\n",
        "    Phi_test = Phi_test / lam      # broadcast over columns\n",
        "    Z_test = Phi_test * (lam ** (t / 2))\n",
        "\n",
        "    return Z_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bc5fe17",
      "metadata": {
        "id": "4bc5fe17"
      },
      "outputs": [],
      "source": [
        "# def nystrom_embed(\n",
        "#     X_test,\n",
        "#     X_train,\n",
        "#     helpers,\n",
        "#     t=1,\n",
        "# ):\n",
        "#     \"\"\"\n",
        "#     Embed X_test into the diffusion space learnt on X_train (Nyström).\n",
        "#     \"\"\"\n",
        "#     sigma        = helpers[\"sigma\"]\n",
        "#     n_neighbors  = helpers[\"n_neighbors\"]\n",
        "#     n_jobs       = helpers[\"n_jobs\"]\n",
        "#     phi_train    = helpers[\"phi_train\"]\n",
        "#     lam          = helpers[\"lam\"]\n",
        "#     inv_sqrt_deg = helpers[\"inv_sqrt_deg\"]\n",
        "\n",
        "#     # neighbour search train←test\n",
        "#     nbrs = NearestNeighbors(\n",
        "#         n_neighbors=n_neighbors,\n",
        "#         metric=\"euclidean\",\n",
        "#         algorithm=\"auto\",\n",
        "#         n_jobs=n_jobs,\n",
        "#     ).fit(X_train)\n",
        "\n",
        "#     dists, idx = nbrs.kneighbors(X_test, return_distance=True)\n",
        "#     dists_sq = dists ** 2\n",
        "#     weights = np.exp(-dists_sq / (sigma ** 2))\n",
        "\n",
        "#     # degree of each new node:  d* = Σ_j w*_j\n",
        "#     d_star = np.sum(weights, axis=1, keepdims=True)\n",
        "#     inv_sqrt_deg_star = 1.0 / np.sqrt(np.clip(d_star, 1e-12, None))\n",
        "\n",
        "#     # normalised affinities  ŵ_{*j} / sqrt(d* d_j)\n",
        "#     scale_train = inv_sqrt_deg[idx]      # (n_test, k)\n",
        "#     A = (inv_sqrt_deg_star * weights) * scale_train\n",
        "\n",
        "#     # Φ_i(x*) = (1 / λ_i) Σ_j A_{*j} Φ_i(x_j)\n",
        "#     Phi_test = (A @ phi_train) / lam\n",
        "\n",
        "#     Z_test = Phi_test * lam ** (t / 2)\n",
        "#     return Z_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69507896",
      "metadata": {
        "id": "69507896"
      },
      "outputs": [],
      "source": [
        "# --------------------------------------------------------------------- #\n",
        "# 4. end-to-end helper                                                  #\n",
        "# --------------------------------------------------------------------- #\n",
        "\n",
        "def diffusion_maps_embed(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    n_components=10,\n",
        "    n_neighbors=30,\n",
        "    sigma=\"median\",\n",
        "    t=2,\n",
        "    n_jobs=-1,\n",
        "):\n",
        "    \"\"\"\n",
        "    Full pipeline → Z_train, Z_test\n",
        "    \"\"\"\n",
        "    lam, phi_train, Z_train, helpers = fit_diffusion_map(\n",
        "        X_train,\n",
        "        n_components,\n",
        "        n_neighbors,\n",
        "        sigma,\n",
        "        t,\n",
        "        n_jobs,\n",
        "    )\n",
        "    Z_test = nystrom_embed(\n",
        "        X_test,\n",
        "        X_train,\n",
        "        helpers,\n",
        "        t,\n",
        "    )\n",
        "    return Z_train, Z_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b8f5bdc",
      "metadata": {
        "id": "8b8f5bdc",
        "outputId": "02720b92-682d-4515-e656-e4c3a792cf52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train shape (8378, 100)    test shape (2793, 100)\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# paste the fast_diffusion_maps.py code (or import it) -----------------------\n",
        "# from fast_diffusion_maps import diffusion_maps_embed\n",
        "\n",
        "# --- 1. File locations ------------------------------------------------------\n",
        "csv_train = Path(r\"C:\\Users\\gpapa\\OneDrive\\My Life\\Education\\2025 YALE MMS\\Term_4S\\T4_E_Adv_Lin_Algebra_p2\\final_project\\glove_train_avg.csv\")\n",
        "\n",
        "csv_test  = Path(r\"C:\\Users\\gpapa\\OneDrive\\My Life\\Education\\2025 YALE MMS\\Term_4S\\T4_E_Adv_Lin_Algebra_p2\\final_project\\glove_test_avg.csv\")\n",
        "\n",
        "# --- 2. Load into NumPy -----------------------------------------------------\n",
        "X_train = pd.read_csv(csv_train, index_col=0).to_numpy(dtype=np.float32)\n",
        "X_test  = pd.read_csv(csv_test, index_col=0).to_numpy(dtype=np.float32)\n",
        "\n",
        "print(\"train shape\", X_train.shape, \"   test shape\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbd15d7e",
      "metadata": {
        "id": "bbd15d7e"
      },
      "source": [
        "Below is a drop-in Jupyter cell that\n",
        "\n",
        "1. loads your two TF-IDF matrices from the specified CSV paths,\n",
        "\n",
        "2. builds a 40-nearest-neighbour Gaussian kernel graph,\n",
        "\n",
        "3. keeps 10 latent diffusion factors,\n",
        "\n",
        "4. embeds the 5 401 test documents by Nyström, and\n",
        "\n",
        "5. writes the coordinates to Z_train.csv and Z_test.csv in the same folder as the source files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43157fe6",
      "metadata": {
        "id": "43157fe6"
      },
      "outputs": [],
      "source": [
        "# --- 3. Diffusion-maps embedding -------------------------------------------\n",
        "Z_train, Z_test = diffusion_maps_embed(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    n_components = 10,      # 10 latent factors\n",
        "    n_neighbors  = 30,      # k-NN size (tune if graph too sparse/dense)\n",
        "    sigma        = \"median\",# bandwidth heuristic  (see note below)\n",
        "    t            = 2,       # horizon: emphasises local phrasing\n",
        "    n_jobs       = -1,      # all cores for neighbour search\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db478649",
      "metadata": {
        "id": "db478649",
        "outputId": "b6c6d8b8-0c70-4d65-c8eb-3b27c53b28d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train shape (8378, 10)    test shape (2793, 10)\n"
          ]
        }
      ],
      "source": [
        "print(\"train shape\", Z_train.shape, \"   test shape\", Z_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daeab214",
      "metadata": {
        "id": "daeab214",
        "outputId": "689cb3c7-7d5b-4e84-d204-3e5479d5a843"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SIMPLE AVG w/o duplicates & t=2\n",
            "Z train matrix:\n",
            "[[-5.06514990e-04 -2.66675184e-04  3.11013587e-05  5.57686322e-02\n",
            "  -7.77807169e-04 -1.36267789e-05  1.62279961e-06 -2.66268521e-07\n",
            "  -1.43657075e-07  5.39011399e-02]]\n",
            "\n",
            "\n",
            "Z test matrix:\n",
            "[[-2.47476937e-04 -6.97087942e-05 -4.22419266e-06 -2.38777813e-03\n",
            "   3.23332027e-04  2.68561307e-05 -1.68791842e-05  2.18382740e-05\n",
            "  -2.58204695e-05 -7.03388138e-05]]\n"
          ]
        }
      ],
      "source": [
        "# 5 Display\n",
        "# -----------------------------------------------------------------\n",
        "print(\"SIMPLE AVG w/o duplicates & t=2\")\n",
        "print(\"Z train matrix:\")\n",
        "print(Z_train[:1, :])\n",
        "print('\\n')\n",
        "print(\"Z test matrix:\")\n",
        "print(Z_test[:1, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68d547fa",
      "metadata": {
        "id": "68d547fa"
      },
      "source": [
        "### TFIDF with duplicates & t=1\n",
        "\n",
        "**Z train matrix:**  \n",
        "**[[-0.00232007 -0.00115001 -0.00079325  0.00066468 -0.00046591  0.00035137 -0.00035245 -0.00036522 -0.00023834 -0.00022062]]**  \n",
        "  \n",
        "   \n",
        "**Z test matrix:**  \n",
        "**[[ 1.57580024e-03  1.30161322e-03  4.43076034e-03  3.55768305e-03 -6.54940916e-04  1.30642522e-03  7.73355226e-04  2.38318630e-04 7.85888666e-05  4.67890067e-05]]**  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd546977",
      "metadata": {
        "id": "fd546977"
      },
      "source": [
        "### TFIDF w/o duplicates & t=1  \n",
        "  \n",
        "Z train matrix:  \n",
        "[[ 0.01146238 -0.01153307  0.01145802 -0.01145705 -0.01151509  0.01152263\n",
        "   0.01118894  0.01159457 -0.01139918  0.01139311]]\n",
        "\n",
        "\n",
        "Z test matrix:  \n",
        "[[ 0.01356615 -0.01365003  0.01356094 -0.01355976 -0.01362857  0.0136375\n",
        "   0.01324168  0.01372175 -0.01349128  0.01348371]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b3b4cb6",
      "metadata": {
        "id": "4b3b4cb6"
      },
      "source": [
        "### TFIDF w/o duplicates & t=5  \n",
        "  \n",
        "Z train matrix:\n",
        "[[ 0.01146233 -0.01153287  0.01145758 -0.01145626 -0.01151386  0.01152086\n",
        "   0.01118658  0.01159138 -0.01139524  0.01138823]]\n",
        "\n",
        "\n",
        "Z test matrix:\n",
        "[[ 0.01356609 -0.0136498   0.01356042 -0.01355883 -0.01362711  0.01363539\n",
        "   0.01323889  0.01371798 -0.01348661  0.01347793]]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa81ebc4",
      "metadata": {
        "id": "fa81ebc4"
      },
      "source": [
        "### TFIDF w/o duplicates & t=2\n",
        "Z train matrix:\n",
        "[[-1.53445594e-03 -8.39407337e-06 -4.84700034e-05  5.85963664e-05\n",
        "  -6.32784183e-05 -2.91732787e-04 -2.91255102e-04 -5.72971236e-02\n",
        "  -5.78337815e-05 -5.01927656e-06]]\n",
        "\n",
        "\n",
        "Z test matrix:\n",
        "[[-1.00735881e-03 -4.54804495e-06 -2.82151424e-05  2.88756919e-05\n",
        "  -2.71958870e-05 -1.70459974e-05 -1.34257639e-06  2.95148373e-03\n",
        "   3.43587736e-05  2.84335936e-05]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d521ee",
      "metadata": {
        "id": "28d521ee",
        "outputId": "9f50c209-8ed5-4118-fd27-df0dd9debd2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓  saved to C:\\Users\\gpapa\\OneDrive\\My Life\\Education\\2025 YALE MMS\\Term_4S\\T4_E_Adv_Lin_Algebra_p2\\final_project\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- 4. Save results --------------------------------------------------------\n",
        "out_dir = csv_train.parent\n",
        "pd.DataFrame(\n",
        "    Z_train,\n",
        "    #index=pd.read_csv(csv_train, index_col=0).index,\n",
        "    columns=[f\"f{i+1}\" for i in range(Z_train.shape[1])]\n",
        ").to_csv(out_dir / \"Z_train_diff_SIMPLE_t2.csv\")\n",
        "\n",
        "pd.DataFrame(\n",
        "    Z_test,\n",
        "    #index=pd.read_csv(csv_test,  index_col=0).index,\n",
        "    columns=[f\"f{i+1}\" for i in range(Z_test.shape[1])]\n",
        ").to_csv(out_dir / \"Z_test_diff_SIMPLE_t2.csv\")\n",
        "\n",
        "print(\"✓  saved to\", out_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47fba849",
      "metadata": {
        "id": "47fba849"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "yale_2025_qf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}